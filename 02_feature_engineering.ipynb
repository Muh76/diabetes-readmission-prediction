{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e637b15",
   "metadata": {},
   "source": [
    "# üöÄ DIABETIC READMISSION PREDICTION - FEATURE ENGINEERING\n",
    "\n",
    "**Phase 2: Advanced Feature Engineering Pipeline**\n",
    "\n",
    "This notebook implements a comprehensive feature engineering strategy for hospital readmission prediction:\n",
    "1. **Clinical Domain Features** - Medical expertise-driven features\n",
    "2. **Demographic & Socioeconomic Features** - Patient risk factors\n",
    "3. **Advanced ML Features** - Performance optimization features\n",
    "\n",
    "**Author**: Data Science Portfolio Project\n",
    "**Date**: August 2024\n",
    "**Goal**: Create production-ready features for ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7175fd",
   "metadata": {},
   "source": [
    "## üìö IMPORTS & SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbedbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ FEATURE ENGINEERING IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy version: {np.__version__}\")\n",
    "print(f\"üìà Matplotlib version: {plt.matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4763c47",
   "metadata": {},
   "source": [
    "## üì• DATA LOADING & PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• LOAD PREPARED DATA\n",
    "print(\"üì• Loading prepared data...\")\n",
    "\n",
    "# Load the main dataset\n",
    "df = pd.read_csv('diabetic_data.csv')\n",
    "\n",
    "# Load our EDA target variable if it exists\n",
    "if 'readmission_30d' not in df.columns:\n",
    "    print(\"‚ö†Ô∏è Target variable not found. Creating it now...\")\n",
    "    df['readmission_30d'] = (df['readmitted'] == '<30').astype(int)\n",
    "\n",
    "print(f\"‚úÖ Data loaded successfully!\")\n",
    "print(f\"üìä Shape: {df.shape}\")\n",
    "print(f\"üéØ Target distribution: {df['readmission_30d'].value_counts().to_dict()}\")\n",
    "print(f\"üìã Columns: {len(df.columns)}\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080c4f0",
   "metadata": {},
   "source": [
    "## üîç DATA QUALITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499aed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç DATA QUALITY ASSESSMENT\n",
    "print(\"üîç ASSESSING DATA QUALITY FOR FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check data types\n",
    "print(\"üìã Data Types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# Check for missing values\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "print(f\"\\n‚ùå Missing Values:\")\n",
    "print(f\"   ‚Ä¢ Total missing: {missing_data.sum():,}\")\n",
    "print(f\"   ‚Ä¢ Columns with missing: {(missing_data > 0).sum()}\")\n",
    "print(f\"   ‚Ä¢ Max missing %: {missing_percent.max():.2f}%\")\n",
    "\n",
    "# Check for '?' values (common in this dataset)\n",
    "question_marks = (df == '?').sum().sum()\n",
    "print(f\"\\n‚ùì Question marks ('?'): {question_marks:,}\")\n",
    "\n",
    "# Memory usage\n",
    "memory_usage = df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"\\nüíæ Memory usage: {memory_usage:.2f} MB\")\n",
    "\n",
    "# Unique values per column\n",
    "print(f\"\\nüî¢ Unique values per column:\")\n",
    "for col in df.columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    if unique_count < 50:  # Only show columns with reasonable unique values\n",
    "        print(f\"   ‚Ä¢ {col}: {unique_count} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2583b006",
   "metadata": {},
   "source": [
    "## üè• PHASE 1: CLINICAL DOMAIN FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ffca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üè• PHASE 1: CLINICAL DOMAIN FEATURES\n",
    "print(\"üè• CREATING CLINICAL DOMAIN FEATURES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. MEDICATION COMPLEXITY SCORE\n",
    "print(\"1Ô∏è‚É£ Creating Medication Complexity Score...\")\n",
    "df['medication_complexity'] = (\n",
    "    df['num_medications'] * 0.4 +\n",
    "    df['number_diagnoses'] * 0.3 +\n",
    "    df['time_in_hospital'] * 0.3\n",
    ")\n",
    "\n",
    "# 2. CLINICAL RISK STRATIFICATION\n",
    "print(\"2Ô∏è‚É£ Creating Clinical Risk Stratification...\")\n",
    "df['clinical_risk_score'] = (\n",
    "    (df['num_procedures'] > df['num_procedures'].median()).astype(int) * 2 +\n",
    "    (df['num_lab_procedures'] > df['num_lab_procedures'].median()).astype(int) * 1.5 +\n",
    "    (df['number_diagnoses'] > df['number_diagnoses'].median()).astype(int) * 2 +\n",
    "    (df['time_in_hospital'] > df['time_in_hospital'].median()).astype(int) * 1.5\n",
    ")\n",
    "\n",
    "# Risk categories\n",
    "df['risk_category'] = pd.cut(df['clinical_risk_score'], \n",
    "                             bins=[0, 2, 4, 6, 10], \n",
    "                             labels=['Low', 'Medium', 'High', 'Critical'])\n",
    "\n",
    "# 3. TREATMENT ADHERENCE INDEX\n",
    "print(\"3Ô∏è‚É£ Creating Treatment Adherence Index...\")\n",
    "df['treatment_adherence'] = (\n",
    "    (df['num_medications'] > 0).astype(int) * 0.4 +\n",
    "    (df['num_procedures'] > 0).astype(int) * 0.3 +\n",
    "    (df['num_lab_procedures'] > 0).astype(int) * 0.3\n",
    ")\n",
    "\n",
    "# 4. COMORBIDITY PATTERNS\n",
    "print(\"4Ô∏è‚É£ Creating Comorbidity Patterns...\")\n",
    "df['comorbidity_count'] = (\n",
    "    (df['diag_1'] != '?').astype(int) +\n",
    "    (df['diag_2'] != '?').astype(int) +\n",
    "    (df['diag_3'] != '?').astype(int)\n",
    ")\n",
    "\n",
    "df['comorbidity_severity'] = df['comorbidity_count'] * df['number_diagnoses']\n",
    "\n",
    "# 5. LABORATORY EFFICIENCY\n",
    "print(\"5Ô∏è‚É£ Creating Laboratory Efficiency Metrics...\")\n",
    "df['lab_efficiency'] = df['num_lab_procedures'] / (df['time_in_hospital'] + 1)\n",
    "df['lab_efficiency'] = df['lab_efficiency'].clip(0, 10)  # Cap at reasonable values\n",
    "\n",
    "# 6. PROCEDURE INTENSITY\n",
    "print(\"6Ô∏è‚É£ Creating Procedure Intensity Metrics...\")\n",
    "df['procedure_intensity'] = df['num_procedures'] / (df['time_in_hospital'] + 1)\n",
    "df['procedure_intensity'] = df['procedure_intensity'].clip(0, 5)\n",
    "\n",
    "print(\"‚úÖ Clinical domain features created successfully!\")\n",
    "print(f\"üìä New features: {[col for col in df.columns if col.startswith(('medication', 'clinical', 'treatment', 'comorbidity', 'lab', 'procedure'))]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674fa479",
   "metadata": {},
   "source": [
    "## üë• PHASE 2: DEMOGRAPHIC & SOCIOECONOMIC FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32ef77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üë• PHASE 2: DEMOGRAPHIC & SOCIOECONOMIC FEATURES\n",
    "print(\"üë• CREATING DEMOGRAPHIC & SOCIOECONOMIC FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. AGE RISK GROUPS\n",
    "print(\"1Ô∏è‚É£ Creating Age Risk Groups...\")\n",
    "def categorize_age_risk(age_str):\n",
    "    if age_str == '?':\n",
    "        return 'Unknown'\n",
    "    elif age_str in ['[0-10)', '[10-20)', '[20-30)']:\n",
    "        return 'Low_Risk'\n",
    "    elif age_str in ['[30-40)', '[40-50)']:\n",
    "        return 'Medium_Risk'\n",
    "    elif age_str in ['[50-60)', '[60-70)']:\n",
    "        return 'High_Risk'\n",
    "    elif age_str in ['[70-80)', '[80-90)', '[90-100)']:\n",
    "        return 'Critical_Risk'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df['age_risk_group'] = df['age'].apply(categorize_age_risk)\n",
    "\n",
    "# 2. INSURANCE-AGE INTERACTION RISK\n",
    "print(\"2Ô∏è‚É£ Creating Insurance-Age Interaction Risk...\")\n",
    "df['insurance_age_risk'] = df['payer_code'].astype(str) + '_' + df['age_risk_group'].astype(str)\n",
    "\n",
    "# 3. GENDER-AGE RISK COMBINATIONS\n",
    "print(\"3Ô∏è‚É£ Creating Gender-Age Risk Combinations...\")\n",
    "df['gender_age_risk'] = df['gender'] + '_' + df['age_risk_group'].astype(str)\n",
    "\n",
    "# 4. SOCIOECONOMIC RISK INDEX\n",
    "print(\"4Ô∏è‚É£ Creating Socioeconomic Risk Index...\")\n",
    "df['socioeconomic_risk'] = (\n",
    "    (df['payer_code'] == '?').astype(int) * 2 +\n",
    "    (df['gender'] == 'Unknown/Invalid').astype(int) * 1 +\n",
    "    (df['age'] == '?').astype(int) * 1\n",
    ")\n",
    "\n",
    "# 5. LENGTH OF STAY RISK CATEGORIES\n",
    "print(\"5Ô∏è‚É£ Creating Length of Stay Risk Categories...\")\n",
    "df['los_risk_category'] = pd.cut(df['time_in_hospital'], \n",
    "                                 bins=[0, 3, 7, 14, 30, 100], \n",
    "                                 labels=['Very_Low', 'Low', 'Medium', 'High', 'Critical'])\n",
    "\n",
    "# 6. READMISSION RISK WINDOWS\n",
    "print(\"6Ô∏è‚É£ Creating Readmission Risk Windows...\")\n",
    "df['readmission_7d'] = (df['readmitted'] == '<30').astype(int)  # 7-day approximation\n",
    "df['readmission_15d'] = (df['readmitted'] == '<30').astype(int)  # 15-day approximation\n",
    "df['readmission_30d'] = (df['readmitted'] == '<30').astype(int)  # 30-day (existing)\n",
    "df['readmission_90d'] = (df['readmitted'].isin(['<30', '>30'])).astype(int)  # 90-day\n",
    "\n",
    "print(\"‚úÖ Demographic & socioeconomic features created successfully!\")\n",
    "print(f\"üìä New features: {[col for col in df.columns if any(x in col for x in ['age_risk', 'insurance', 'gender', 'socioeconomic', 'los_risk', 'readmission_'])]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da145ef",
   "metadata": {},
   "source": [
    "## ü§ñ PHASE 3: ADVANCED ML FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ PHASE 3: ADVANCED ML FEATURES\n",
    "print(\"ü§ñ CREATING ADVANCED ML FEATURES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. POLYNOMIAL INTERACTIONS\n",
    "print(\"1Ô∏è‚É£ Creating Polynomial Interactions...\")\n",
    "df['age_medication_interaction'] = df['age_risk_group'].astype(str) + '_' + df['num_medications'].astype(str)\n",
    "df['diagnosis_procedure_interaction'] = df['number_diagnoses'] * df['num_procedures']\n",
    "df['time_medication_efficiency'] = df['time_in_hospital'] * df['num_medications']\n",
    "\n",
    "# 2. RATIO FEATURES\n",
    "print(\"2Ô∏è‚É£ Creating Ratio Features...\")\n",
    "df['medications_per_day'] = df['num_medications'] / (df['time_in_hospital'] + 1)\n",
    "df['procedures_per_day'] = df['num_procedures'] / (df['time_in_hospital'] + 1)\n",
    "df['lab_procedures_per_day'] = df['num_lab_procedures'] / (df['time_in_hospital'] + 1)\n",
    "df['diagnoses_per_day'] = df['number_diagnoses'] / (df['time_in_hospital'] + 1)\n",
    "\n",
    "# 3. BINNED NUMERICAL FEATURES\n",
    "print(\"3Ô∏è‚É£ Creating Binned Numerical Features...\")\n",
    "df['medications_binned'] = pd.cut(df['num_medications'], \n",
    "                                  bins=[0, 5, 10, 15, 20, 100], \n",
    "                                  labels=['Very_Low', 'Low', 'Medium', 'High', 'Very_High'])\n",
    "\n",
    "df['diagnoses_binned'] = pd.cut(df['number_diagnoses'], \n",
    "                                 bins=[0, 3, 6, 9, 12, 100], \n",
    "                                 labels=['Very_Low', 'Low', 'Medium', 'High', 'Very_High'])\n",
    "\n",
    "# 4. AGGREGATION FEATURES\n",
    "print(\"4Ô∏è‚É£ Creating Aggregation Features...\")\n",
    "df['total_procedures'] = df['num_procedures'] + df['num_lab_procedures']\n",
    "df['total_clinical_activities'] = df['num_procedures'] + df['num_lab_procedures'] + df['num_medications']\n",
    "df['clinical_intensity'] = df['total_clinical_activities'] / (df['time_in_hospital'] + 1)\n",
    "\n",
    "# 5. CATEGORICAL ENCODING PREPARATION\n",
    "print(\"5Ô∏è‚É£ Preparing Categorical Encoding...\")\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"üìã Categorical columns identified: {len(categorical_columns)}\")\n",
    "print(f\"   ‚Ä¢ High cardinality columns: {[col for col in categorical_columns if df[col].nunique() > 20]}\")\n",
    "\n",
    "print(\"‚úÖ Advanced ML features created successfully!\")\n",
    "print(f\"üìä New features: {[col for col in df.columns if any(x in col for x in ['interaction', 'ratio', 'binned', 'total', 'intensity'])]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c909d9e5",
   "metadata": {},
   "source": [
    "## üìä FEATURE ANALYSIS & VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a3bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä FEATURE ANALYSIS & VALIDATION\n",
    "print(\"üìä ANALYZING ENGINEERED FEATURES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. FEATURE SUMMARY STATISTICS\n",
    "print(\"1Ô∏è‚É£ Feature Summary Statistics...\")\n",
    "new_features = [col for col in df.columns if col not in ['readmitted', 'readmission_30d']]\n",
    "print(f\"üìä Total features created: {len(new_features)}\")\n",
    "\n",
    "# 2. FEATURE CORRELATION ANALYSIS\n",
    "print(\"2Ô∏è‚É£ Feature Correlation Analysis...\")\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "\n",
    "# Find highly correlated features\n",
    "high_corr_features = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            high_corr_features.append((correlation_matrix.columns[i], \n",
    "                                     correlation_matrix.columns[j], \n",
    "                                     correlation_matrix.iloc[i, j]))\n",
    "\n",
    "print(f\"üîó Highly correlated feature pairs (|r| > 0.8): {len(high_corr_features)}\")\n",
    "for pair in high_corr_features[:5]:  # Show first 5\n",
    "    print(f\"   ‚Ä¢ {pair[0]} ‚Üî {pair[1]}: r = {pair[2]:.3f}\")\n",
    "\n",
    "# 3. FEATURE IMPORTANCE ANALYSIS\n",
    "print(\"3Ô∏è‚É£ Feature Importance Analysis...\")\n",
    "try:\n",
    "    # Prepare data for feature importance\n",
    "    feature_cols = [col for col in df.columns if col not in ['readmitted', 'readmission_30d'] and df[col].dtype in ['int64', 'float64']]\n",
    "    X_temp = df[feature_cols].fillna(0)\n",
    "    y_temp = df['readmission_30d']\n",
    "    \n",
    "    # Train a simple model for feature importance\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_temp, y_temp)\n",
    "    \n",
    "    # Get feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': rf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"üèÜ Top 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Feature importance analysis failed: {e}\")\n",
    "    print(\"   This is normal for some data types. Continuing...\")\n",
    "\n",
    "print(\"‚úÖ Feature analysis completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6ac7c",
   "metadata": {},
   "source": [
    "## üìà FEATURE VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà FEATURE VISUALIZATION\n",
    "print(\"üìà CREATING FEATURE VISUALIZATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create comprehensive visualization dashboard\n",
    "plt.figure(figsize=(24, 16))\n",
    "\n",
    "# 1. Clinical Risk Distribution\n",
    "plt.subplot(3, 4, 1)\n",
    "df['risk_category'].value_counts().plot(kind='bar', color='darkred')\n",
    "plt.title('Clinical Risk Category Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Risk Category')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 2. Age Risk Groups\n",
    "plt.subplot(3, 4, 2)\n",
    "df['age_risk_group'].value_counts().plot(kind='bar', color='darkblue')\n",
    "plt.title('Age Risk Group Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Age Risk Group')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 3. Medication Complexity Distribution\n",
    "plt.subplot(3, 4, 3)\n",
    "plt.hist(df['medication_complexity'], bins=30, color='lightblue', alpha=0.7, edgecolor='black')\n",
    "plt.title('Medication Complexity Score Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Medication Complexity Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 4. Clinical Risk vs Readmission\n",
    "plt.subplot(3, 4, 4)\n",
    "risk_readmission = df.groupby(['risk_category', 'readmission_30d']).size().unstack(fill_value=0)\n",
    "risk_readmission['readmission_rate'] = (risk_readmission[1] / risk_readmission.sum(axis=1) * 100).round(2)\n",
    "risk_readmission['readmission_rate'].plot(kind='bar', color='darkgreen')\n",
    "plt.title('Readmission Rate by Clinical Risk', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Clinical Risk Category')\n",
    "plt.ylabel('Readmission Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 5. Length of Stay Risk\n",
    "plt.subplot(3, 4, 5)\n",
    "df['los_risk_category'].value_counts().plot(kind='bar', color='purple')\n",
    "plt.title('Length of Stay Risk Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('LOS Risk Category')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 6. Treatment Adherence\n",
    "plt.subplot(3, 4, 6)\n",
    "plt.hist(df['treatment_adherence'], bins=20, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "plt.title('Treatment Adherence Index Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Treatment Adherence Index')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 7. Comorbidity Severity\n",
    "plt.subplot(3, 4, 7)\n",
    "plt.hist(df['comorbidity_severity'], bins=20, color='lightcoral', alpha=0.7, edgecolor='black')\n",
    "plt.title('Comorbidity Severity Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Comorbidity Severity Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 8. Lab Efficiency\n",
    "plt.subplot(3, 4, 8)\n",
    "plt.hist(df['lab_efficiency'], bins=20, color='lightyellow', alpha=0.7, edgecolor='black')\n",
    "plt.title('Laboratory Efficiency Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Lab Efficiency Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 9. Socioeconomic Risk\n",
    "plt.subplot(3, 4, 9)\n",
    "df['socioeconomic_risk'].value_counts().sort_index().plot(kind='bar', color='orange')\n",
    "plt.title('Socioeconomic Risk Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Socioeconomic Risk Score')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# 10. Clinical Intensity\n",
    "plt.subplot(3, 4, 10)\n",
    "plt.hist(df['clinical_intensity'], bins=20, color='lightsteelblue', alpha=0.7, edgecolor='black')\n",
    "plt.title('Clinical Intensity Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Clinical Intensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 11. Readmission Risk Windows\n",
    "plt.subplot(3, 4, 11)\n",
    "readmission_windows = ['readmission_7d', 'readmission_15d', 'readmission_30d', 'readmission_90d']\n",
    "readmission_rates = [df[col].mean() * 100 for col in readmission_windows]\n",
    "plt.bar(['7d', '15d', '30d', '90d'], readmission_rates, color=['red', 'orange', 'yellow', 'green'])\n",
    "plt.title('Readmission Rates by Time Window', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Time Window')\n",
    "plt.ylabel('Readmission Rate (%)')\n",
    "\n",
    "# 12. Feature Correlation Heatmap (Top 15)\n",
    "plt.subplot(3, 4, 12)\n",
    "top_features = feature_importance.head(15)['feature'].tolist() if 'feature_importance' in locals() else numerical_features[:15]\n",
    "corr_subset = df[top_features].corr()\n",
    "sns.heatmap(corr_subset, annot=False, cmap='coolwarm', center=0, square=True, cbar_kws={'shrink': 0.8})\n",
    "plt.title('Top Features Correlation Heatmap', fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Feature visualizations created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e5137",
   "metadata": {},
   "source": [
    "## üíæ FEATURE ENGINEERING SUMMARY & EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ FEATURE ENGINEERING SUMMARY & EXPORT\n",
    "print(\"üíæ FEATURE ENGINEERING SUMMARY & EXPORT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. FEATURE SUMMARY\n",
    "print(\"1Ô∏è‚É£ FEATURE ENGINEERING SUMMARY:\")\n",
    "print(f\"   üìä Original features: {len([col for col in df.columns if col in ['readmitted', 'readmission_30d']])}\")\n",
    "print(f\"   üöÄ New features created: {len([col for col in df.columns if col not in ['readmitted', 'readmission_30d']])}\")\n",
    "print(f\"   üéØ Total features: {len(df.columns)}\")\n",
    "\n",
    "# 2. FEATURE CATEGORIES\n",
    "print(\"\\n2Ô∏è‚É£ FEATURE CATEGORIES:\")\n",
    "clinical_features = [col for col in df.columns if any(x in col for x in ['medication', 'clinical', 'treatment', 'comorbidity', 'lab', 'procedure'])]\n",
    "demographic_features = [col for col in df.columns if any(x in col for x in ['age_risk', 'insurance', 'gender', 'socioeconomic', 'los_risk'])]\n",
    "ml_features = [col for col in df.columns if any(x in col for x in ['interaction', 'ratio', 'binned', 'total', 'intensity'])]\n",
    "\n",
    "print(f\"   üè• Clinical features: {len(clinical_features)}\")\n",
    "print(f\"   üë• Demographic features: {len(demographic_features)}\")\n",
    "print(f\"   ü§ñ ML features: {len(ml_features)}\")\n",
    "\n",
    "# 3. DATA QUALITY CHECK\n",
    "print(\"\\n3Ô∏è‚É£ DATA QUALITY CHECK:\")\n",
    "missing_after = df.isnull().sum().sum()\n",
    "print(f\"   ‚ùå Missing values: {missing_after:,}\")\n",
    "print(f\"   ‚úÖ Data shape: {df.shape}\")\n",
    "print(f\"   üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# 4. EXPORT ENGINEERED DATASET\n",
    "print(\"\\n4Ô∏è‚É£ EXPORTING ENGINEERED DATASET...\")\n",
    "output_filename = 'diabetic_data_engineered.csv'\n",
    "df.to_csv(output_filename, index=False)\n",
    "print(f\"   ‚úÖ Dataset exported to: {output_filename}\")\n",
    "print(f\"   üìÅ File size: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# 5. FEATURE LIST EXPORT\n",
    "print(\"\\n5Ô∏è‚É£ EXPORTING FEATURE LIST...\")\n",
    "feature_list = pd.DataFrame({\n",
    "    'feature_name': df.columns.tolist(),\n",
    "    'feature_type': df.dtypes.astype(str).tolist(),\n",
    "    'unique_values': [df[col].nunique() for col in df.columns],\n",
    "    'missing_values': df.isnull().sum().tolist(),\n",
    "    'category': ['Target' if col in ['readmitted', 'readmission_30d'] else \n",
    "                 'Clinical' if col in clinical_features else\n",
    "                 'Demographic' if col in demographic_features else\n",
    "                 'ML' if col in ml_features else 'Original' for col in df.columns]\n",
    "})\n",
    "\n",
    "feature_list.to_csv('feature_engineering_summary.csv', index=False)\n",
    "print(f\"   ‚úÖ Feature list exported to: feature_engineering_summary.csv\")\n",
    "\n",
    "print(\"\\nüéâ FEATURE ENGINEERING COMPLETED SUCCESSFULLY! üéâ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä Total features: {len(df.columns)}\")\n",
    "print(f\"üöÄ New features created: {len([col for col in df.columns if col not in ['readmitted', 'readmission_30d']])}\")\n",
    "print(f\"üíæ Dataset exported: {output_filename}\")\n",
    "print(f\"üìã Feature summary: feature_engineering_summary.csv\")\n",
    "print(\"\\nüéØ NEXT STEPS:\")\n",
    "print(\"   1. Review feature engineering summary\")\n",
    "print(\"   2. Proceed to Power BI dashboard creation\")\n",
    "print(\"   3. Model development and training\")\n",
    "print(\"   4. MLOps pipeline implementation\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
