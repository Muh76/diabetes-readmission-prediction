{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data validation & preprocessing\n",
    "import sklearn\n",
    "import pandera as pa\n",
    "from pandera import Column, DataFrameSchema\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "\n",
    "# Advanced feature engineering\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# SMOTE balancing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# MLOps & tracking\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Performance monitoring\n",
    "import time\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['font.size']=6\n",
    "plt.rcParams['font.family']='serif'\n",
    "plt.rcParams['font.weight']='bold'\n",
    "plt.rcParams['figure.figsize']=(10,5)\n",
    "plt.rcParams['figure.dpi']=300\n",
    "plt.rcParams['savefig.dpi']=300\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"ÔøΩÔøΩ NumPy version: {np.__version__}\")\n",
    "print(f\"ÔøΩÔøΩ Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"ÔøΩÔøΩ Pandera version: {pa.__version__}\")\n",
    "print(f\"ü§ñ Scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"üìä MLflow version: {mlflow.__version__}\")\n",
    "\n",
    "# Initialize MLflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"diabetic_readmission_pipeline\")\n",
    "\n",
    "print(f\"ÔøΩÔøΩ MLflow experiment: {mlflow.get_experiment_by_name('diabetic_readmission_pipeline')}\")\n",
    "\n",
    "# Performance monitoring setup\n",
    "start_time = time.time()\n",
    "initial_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
    "\n",
    "print(f\"\\nüìä Performance Monitoring:\")\n",
    "print(f\"   ‚Ä¢ Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"   ‚Ä¢ Initial memory usage: {initial_memory:.2f} MB\")\n",
    "print(f\"   ‚Ä¢ CPU cores available: {psutil.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"/Users/javadbeni/Desktop/Diabetes_Phase1_1/diabetic_data.csv\"\n",
    "\n",
    "df=pd.read_csv(file_path)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.describe()\n",
    "df.isnull().sum().sort_values(ascending=False)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data=df.isnull().sum().sort_values(ascending=False)\n",
    "missing_percent=(missing_data/len(df))*100\n",
    "missing_summary=pd.DataFrame({\n",
    "    'Column':missing_data.index,\n",
    "    'Missing_Count':missing_data.values,\n",
    "    'Missing_Percent':missing_percent.values,\n",
    "    'Data_Type':df.dtypes.values\n",
    "\n",
    "})\n",
    "print(missing_summary[missing_summary.Missing_Percent>0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Subplot 1: Missing percentage\n",
    "plt.subplot(1, 2, 1)\n",
    "missing_summary[missing_summary['Missing_Percent'] > 0]['Missing_Percent'].plot(kind='bar')\n",
    "plt.title('Missing Values by Column (%)')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Missing Percentage')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Subplot 2: Missing count\n",
    "plt.subplot(1, 2, 2)\n",
    "missing_summary[missing_summary['Missing_Percent'] > 0]['Missing_Count'].plot(kind='bar')\n",
    "plt.title('Missing Values by Column (Count)')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Missing Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Data types\n",
    "print('Data Type Summary')\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Mixed data types in object columns\n",
    "print('Potential Data types issues')\n",
    "\n",
    "mixed_type_columns=[]\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    unique_types=df[col].dropna().apply(type).nunique()\n",
    "    if unique_types>1:\n",
    "        mixed_type_columns.append(col)\n",
    "        print(f'‚ö†Ô∏è {col}:{unique_types} different types detected')\n",
    "if not mixed_type_columns:\n",
    "    print('‚úÖ No mixed type columns detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Numerical Columns might be Categorical\n",
    "numeric_cols=df.select_dtypes(include=['int64','float64']).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    unique_val=df[col].nunique()\n",
    "    if unique_val<20:\n",
    "        print(f' ‚ö†Ô∏è {col}:{unique_val} unique values , it might be potential categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Categorical Columns\n",
    "categorical_cols=df.select_dtypes(include=['object']).columns\n",
    "print(f'Found {len(categorical_cols)} categorical columns')\n",
    "for col in categorical_cols:\n",
    "    unique_vals=df[col].nunique()\n",
    "    print(f'{col}:{unique_vals} unique values')\n",
    "    if unique_vals>=20:\n",
    "        print(f' ‚ö†Ô∏è {col}:{unique_vals} high cardinality , encoding might be needed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Values Correlation Analysis with the Target Variable\n",
    "print('Missing Values Correlation Matrix ( Columns with >5% missings)')\n",
    "high_missing_cols=missing_summary[missing_summary.Missing_Percent>5]['Column'].tolist()\n",
    "\n",
    "if len(high_missing_cols)>0:\n",
    "    missing_corr=df[high_missing_cols].isnull().corr()\n",
    "    print(missing_corr)\n",
    "\n",
    "    #Visualize the Correlation Matrix\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(missing_corr,annot=True,cmap='coolwarm',center=0)\n",
    "    plt.title('Columns with Missing Values Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('‚úÖ No columns with missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nÔøΩÔøΩ 6. SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"üîç Key Findings:\")\n",
    "print(f\"   ‚Ä¢ Total rows: {len(df):,}\")\n",
    "print(f\"   ‚Ä¢ Total columns: {len(df.columns)}\")\n",
    "print(f\"   ‚Ä¢ Columns with missing values: {len(missing_summary[missing_summary['Missing_Percent'] > 0])}\")\n",
    "\n",
    "\n",
    "print(\"\\nÔøΩÔøΩ Critical Issues to Address:\")\n",
    "critical_missing = missing_summary[missing_summary['Missing_Percent'] > 20]\n",
    "if not critical_missing.empty:\n",
    "    for _, row in critical_missing.iterrows():\n",
    "        print(f\"   ‚Ä¢ {row['Column']}: {row['Missing_Percent']:.1f}% missing\")\n",
    "else:\n",
    "    print(\"   ‚Ä¢ No critical missing value issues (>20%)\")\n",
    "\n",
    "print(\"\\nüí° Recommendations:\")\n",
    "print(\"   ‚Ä¢ Consider imputation strategies for columns with <20% missing\")\n",
    "print(\"   ‚Ä¢ Investigate high cardinality categorical variables\")\n",
    "print(\"   ‚Ä¢ Plan encoding strategies for categorical variables\")\n",
    "print(\"   ‚Ä¢ Monitor memory usage during feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ TARGET VARIABLE CREATION\n",
    "print(\"üéØ CREATING TARGET VARIABLE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check current readmission distribution\n",
    "print(\"Current readmission distribution:\")\n",
    "print(df['readmitted'].value_counts())\n",
    "print(\"\\nDetailed breakdown:\")\n",
    "print(df['readmitted'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Create binary target variable for 30-day readmission\n",
    "df['readmission_30d'] = (df['readmitted'] == '<30').astype(int)\n",
    "\n",
    "# Verify target creation\n",
    "print(f\"\\n‚úÖ Target variable 'readmission_30d' created:\")\n",
    "print(f\"   ‚Ä¢ 0 (No readmission): {(df['readmission_30d'] == 0).sum():,} patients\")\n",
    "print(f\"   ‚Ä¢ 1 (Readmission <30 days): {(df['readmission_30d'] == 1).sum():,} patients\")\n",
    "print(f\"   ‚Ä¢ Readmission rate: {(df['readmission_30d'] == 1).mean() * 100:.2f}%\")\n",
    "\n",
    "# Check for any missing values in target\n",
    "if df['readmission_30d'].isnull().sum() > 0:\n",
    "    print(f\"‚ö†Ô∏è Warning: {df['readmission_30d'].isnull().sum()} missing values in target\")\n",
    "else:\n",
    "    print(\"‚úÖ No missing values in target variable\")\n",
    "\n",
    "# Save target variable info for later use\n",
    "target_info = {\n",
    "    'total_patients': len(df),\n",
    "    'readmission_count': df['readmission_30d'].sum(),\n",
    "    'readmission_rate': df['readmission_30d'].mean(),\n",
    "    'class_balance': 'Imbalanced' if df['readmission_30d'].mean() < 0.1 else 'Balanced'\n",
    "}\n",
    "\n",
    "print(f\"\\nüìä Target Variable Summary:\")\n",
    "print(f\"   ‚Ä¢ Class balance: {target_info['class_balance']}\")\n",
    "print(f\"   ‚Ä¢ Imbalance ratio: 1:{int((1-target_info['readmission_rate'])/target_info['readmission_rate'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üè• CLINICAL RISK STRATIFICATION\n",
    "print(\"üè• CLINICAL RISK STRATIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create clinical risk categories based on number of diagnoses\n",
    "df['clinical_risk'] = pd.cut(df['number_diagnoses'], \n",
    "                            bins=[0, 3, 6, 10, 100], \n",
    "                            labels=['Low', 'Medium', 'High', 'Critical'])\n",
    "\n",
    "# Analyze readmission by clinical risk\n",
    "risk_analysis = df.groupby(['clinical_risk', 'readmission_30d']).size().unstack(fill_value=0)\n",
    "risk_analysis['total'] = risk_analysis.sum(axis=1)\n",
    "risk_analysis['readmission_rate'] = (risk_analysis[1] / risk_analysis['total'] * 100).round(2)\n",
    "\n",
    "print(\"Readmission Analysis by Clinical Risk:\")\n",
    "print(risk_analysis)\n",
    "\n",
    "# Visualize the relationship\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Count by risk category\n",
    "plt.subplot(1, 3, 1)\n",
    "risk_analysis[['total']].plot(kind='bar', color='skyblue', ax=plt.gca())\n",
    "plt.title('Patient Count by Clinical Risk Category', fontweight='bold')\n",
    "plt.xlabel('Clinical Risk Category')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Subplot 2: Readmission rate by risk category\n",
    "plt.subplot(1, 3, 2)\n",
    "risk_analysis['readmission_rate'].plot(kind='bar', color='coral', ax=plt.gca())\n",
    "plt.title('Readmission Rate by Clinical Risk Category', fontweight='bold')\n",
    "plt.xlabel('Clinical Risk Category')\n",
    "plt.ylabel('Readmission Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Subplot 3: Stacked bar chart showing readmission vs no readmission\n",
    "plt.subplot(1, 3, 3)\n",
    "risk_analysis[[0, 1]].plot(kind='bar', stacked=True, ax=plt.gca())\n",
    "plt.title('Readmission Status by Clinical Risk Category', fontweight='bold')\n",
    "plt.xlabel('Clinical Risk Category')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(['No Readmission', 'Readmission <30 days'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Clinical risk stratification completed:\")\n",
    "print(f\"   ‚Ä¢ Low risk (1-3 diagnoses): {risk_analysis.loc['Low', 'total']:,} patients\")\n",
    "print(f\"   ‚Ä¢ Medium risk (4-6 diagnoses): {risk_analysis.loc['Medium', 'total']:,} patients\")\n",
    "print(f\"   ‚Ä¢ High risk (7-10 diagnoses): {risk_analysis.loc['High', 'total']:,} patients\")\n",
    "print(f\"   ‚Ä¢ Critical risk (11+ diagnoses): {risk_analysis.loc['Critical', 'total']:,} patients\")\n",
    "\n",
    "# Save risk analysis for later use\n",
    "clinical_risk_summary = {\n",
    "    'low_risk_patients': risk_analysis.loc['Low', 'total'],\n",
    "    'medium_risk_patients': risk_analysis.loc['Medium', 'total'],\n",
    "    'high_risk_patients': risk_analysis.loc['High', 'total'],\n",
    "    'critical_risk_patients': risk_analysis.loc['Critical', 'total'],\n",
    "    'highest_readmission_rate': risk_analysis['readmission_rate'].max(),\n",
    "    'highest_readmission_category': risk_analysis['readmission_rate'].idxmax()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíä TREATMENT COMPLEXITY ANALYSIS\n",
    "print(\"üíä TREATMENT COMPLEXITY ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create treatment complexity score\n",
    "df['treatment_complexity'] = (\n",
    "    df['num_procedures'] * 0.3 +\n",
    "    df['num_medications'] * 0.4 +\n",
    "    df['number_diagnoses'] * 0.3\n",
    ")\n",
    "\n",
    "# Categorize treatment complexity\n",
    "df['complexity_level'] = pd.cut(df['treatment_complexity'], \n",
    "                               bins=[0, 2, 4, 6, 20], \n",
    "                               labels=['Low', 'Medium', 'High', 'Critical'])\n",
    "\n",
    "# Analyze readmission by treatment complexity\n",
    "complexity_analysis = df.groupby(['complexity_level', 'readmission_30d']).size().unstack(fill_value=0)\n",
    "complexity_analysis['total'] = complexity_analysis.sum(axis=1)\n",
    "complexity_analysis['readmission_rate'] = (complexity_analysis[1] / complexity_analysis['total'] * 100).round(2)\n",
    "\n",
    "print(\"Readmission Analysis by Treatment Complexity:\")\n",
    "print(complexity_analysis)\n",
    "\n",
    "# Visualize treatment complexity distribution\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Subplot 1: Treatment complexity score distribution\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.hist(df['treatment_complexity'], bins=30, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "plt.title('Distribution of Treatment Complexity Score', fontweight='bold')\n",
    "plt.xlabel('Treatment Complexity Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Subplot 2: Readmission rate by complexity level\n",
    "plt.subplot(1, 4, 2)\n",
    "complexity_analysis['readmission_rate'].plot(kind='bar', color='orange')\n",
    "plt.title('Readmission Rate by Complexity Level', fontweight='bold')\n",
    "plt.xlabel('Complexity Level')\n",
    "plt.ylabel('Readmission Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Subplot 3: Box plot of complexity by readmission status\n",
    "plt.subplot(1, 4, 3)\n",
    "df.boxplot(column='treatment_complexity', by='readmission_30d', ax=plt.gca())\n",
    "plt.title('Treatment Complexity by Readmission Status', fontweight='bold')\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "# Subplot 4: Scatter plot of complexity vs readmission\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.scatter(df[df['readmission_30d']==0]['treatment_complexity'], \n",
    "           df[df['readmission_30d']==0]['number_diagnoses'], \n",
    "           alpha=0.6, label='No Readmission', color='blue')\n",
    "plt.scatter(df[df['readmission_30d']==1]['treatment_complexity'], \n",
    "           df[df['readmission_30d']==1]['number_diagnoses'], \n",
    "           alpha=0.6, label='Readmission <30 days', color='red')\n",
    "plt.xlabel('Treatment Complexity Score')\n",
    "plt.ylabel('Number of Diagnoses')\n",
    "plt.title('Complexity vs Diagnoses by Readmission Status', fontweight='bold')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Treatment complexity analysis completed:\")\n",
    "print(f\"   ‚Ä¢ Average complexity score: {df['treatment_complexity'].mean():.2f}\")\n",
    "print(f\"   ‚Ä¢ Complexity range: {df['treatment_complexity'].min():.1f} - {df['treatment_complexity'].max():.1f}\")\n",
    "print(f\"   ‚Ä¢ Standard deviation: {df['treatment_complexity'].std():.2f}\")\n",
    "\n",
    "# Save complexity analysis for later use\n",
    "complexity_summary = {\n",
    "    'avg_complexity': df['treatment_complexity'].mean(),\n",
    "    'min_complexity': df['treatment_complexity'].min(),\n",
    "    'max_complexity': df['treatment_complexity'].max(),\n",
    "    'std_complexity': df['treatment_complexity'].std(),\n",
    "    'highest_complexity_readmission_rate': complexity_analysis.loc['Critical', 'readmission_rate']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí∞ INSURANCE & SOCIOECONOMIC ANALYSIS\n",
    "print(\"üí∞ INSURANCE & SOCIOECONOMIC ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze readmission by insurance type\n",
    "insurance_analysis = df.groupby(['payer_code', 'readmission_30d']).size().unstack(fill_value=0)\n",
    "insurance_analysis['total'] = insurance_analysis.sum(axis=1)\n",
    "insurance_analysis['readmission_rate'] = (insurance_analysis[1] / insurance_analysis['total'] * 100).round(2)\n",
    "\n",
    "# Sort by readmission rate for better insights\n",
    "insurance_analysis = insurance_analysis.sort_values('readmission_rate', ascending=False)\n",
    "\n",
    "print(\"Top 15 Insurance Types by Readmission Rate:\")\n",
    "print(insurance_analysis.head(15))\n",
    "\n",
    "# Create socioeconomic risk score\n",
    "df['socioeconomic_risk'] = 0\n",
    "\n",
    "# Add risk points based on various factors\n",
    "df.loc[df['payer_code'] == 'MC', 'socioeconomic_risk'] += 2      # Medicaid\n",
    "df.loc[df['payer_code'] == 'MD', 'socioeconomic_risk'] += 1      # Medicare\n",
    "df.loc[df['race'] == 'AfricanAmerican', 'socioeconomic_risk'] += 1\n",
    "df.loc[df['age'] == '?', 'socioeconomic_risk'] += 1              # Unknown age\n",
    "df.loc[df['weight'] == '?', 'socioeconomic_risk'] += 1            # Unknown weight\n",
    "\n",
    "# Categorize socioeconomic risk\n",
    "df['socioeconomic_level'] = pd.cut(df['socioeconomic_risk'], \n",
    "                                  bins=[0, 1, 2, 3, 10], \n",
    "                                  labels=['Low', 'Medium', 'High', 'Critical'])\n",
    "\n",
    "# Analyze readmission by socioeconomic risk\n",
    "socio_analysis = df.groupby(['socioeconomic_level', 'readmission_30d']).size().unstack(fill_value=0)\n",
    "socio_analysis['total'] = socio_analysis.sum(axis=1)\n",
    "socio_analysis['readmission_rate'] = (socio_analysis[1] / socio_analysis['total'] * 100).round(2)\n",
    "\n",
    "print(\"\\nReadmission Analysis by Socioeconomic Risk:\")\n",
    "print(socio_analysis)\n",
    "\n",
    "# Visualize socioeconomic analysis\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Subplot 1: Insurance readmission rates (top 15)\n",
    "plt.subplot(1, 4, 1)\n",
    "top_insurance = insurance_analysis.head(15)\n",
    "top_insurance['readmission_rate'].plot(kind='bar', color='purple')\n",
    "plt.title('Top 15 Insurance Types by Readmission Rate', fontweight='bold')\n",
    "plt.xlabel('Insurance Type')\n",
    "plt.ylabel('Readmission Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Subplot 2: Socioeconomic risk distribution\n",
    "plt.subplot(1, 4, 2)\n",
    "df['socioeconomic_risk'].value_counts().sort_index().plot(kind='bar', color='brown')\n",
    "plt.title('Distribution of Socioeconomic Risk Scores', fontweight='bold')\n",
    "plt.xlabel('Risk Score')\n",
    "plt.ylabel('Number of Patients')\n",
    "\n",
    "# Subplot 3: Readmission rate by socioeconomic level\n",
    "plt.subplot(1, 4, 3)\n",
    "socio_analysis['readmission_rate'].plot(kind='bar', color='red')\n",
    "plt.title('Readmission Rate by Socioeconomic Risk Level', fontweight='bold')\n",
    "plt.xlabel('Socioeconomic Risk Level')\n",
    "plt.ylabel('Readmission Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Subplot 4: Race analysis\n",
    "plt.subplot(1, 4, 4)\n",
    "race_analysis = df.groupby(['race', 'readmission_30d']).size().unstack(fill_value=0)\n",
    "race_analysis['total'] = race_analysis.sum(axis=1)\n",
    "race_analysis['readmission_rate'] = (race_analysis[1] / race_analysis['total'] * 100).round(2)\n",
    "race_analysis['readmission_rate'].plot(kind='bar', color='green')\n",
    "plt.title('Readmission Rate by Race', fontweight='bold')\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Readmission Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Socioeconomic analysis completed:\")\n",
    "print(f\"   ‚Ä¢ Average socioeconomic risk score: {df['socioeconomic_risk'].mean():.2f}\")\n",
    "print(f\"   ‚Ä¢ Risk score range: {df['socioeconomic_risk'].min()} - {df['socioeconomic_risk'].max()}\")\n",
    "\n",
    "# Save socioeconomic analysis for later use\n",
    "socioeconomic_summary = {\n",
    "    'avg_risk_score': df['socioeconomic_risk'].mean(),\n",
    "    'min_risk_score': df['socioeconomic_risk'].min(),\n",
    "    'max_risk_score': df['socioeconomic_risk'].max(),\n",
    "    'highest_risk_readmission_rate': socio_analysis.loc['Critical', 'readmission_rate'],\n",
    "    'medicaid_patients': (df['payer_code'] == 'MC').sum(),\n",
    "    'medicare_patients': (df['payer_code'] == 'MD').sum()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ ADVANCED FEATURE ENGINEERING\n",
    "print(\"üöÄ ADVANCED FEATURE ENGINEERING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Medication adherence score\n",
    "df['medication_adherence'] = df['num_medications'] / (df['number_diagnoses'] + 1)\n",
    "df['medication_adherence'] = df['medication_adherence'].clip(0, 5)\n",
    "\n",
    "# 2. Hospital utilization score\n",
    "df['hospital_utilization'] = (\n",
    "    df['number_outpatient'] * 0.3 +\n",
    "    df['number_emergency'] * 0.4 +\n",
    "    df['number_inpatient'] * 0.3\n",
    ")\n",
    "\n",
    "# 3. Lab procedure efficiency\n",
    "df['lab_efficiency'] = df['num_lab_procedures'] / (df['time_in_hospital'] + 1)\n",
    "\n",
    "# 4. Age group categorization - FIXED for your data format\n",
    "print(\"Processing age groups...\")\n",
    "# First, let's see what's in the age column\n",
    "print(\"Unique age values:\", df['age'].unique())\n",
    "\n",
    "# Create age groups based on the string format in your data\n",
    "def categorize_age(age_str):\n",
    "    if age_str == '?':\n",
    "        return 'Unknown'\n",
    "    elif age_str == '[0-10)':\n",
    "        return 'Young'\n",
    "    elif age_str == '[10-20)':\n",
    "        return 'Young'\n",
    "    elif age_str == '[20-30)':\n",
    "        return 'Young'\n",
    "    elif age_str == '[30-40)':\n",
    "        return 'Middle'\n",
    "    elif age_str == '[40-50)':\n",
    "        return 'Middle'\n",
    "    elif age_str == '[50-60)':\n",
    "        return 'Senior'\n",
    "    elif age_str == '[60-70)':\n",
    "        return 'Senior'\n",
    "    elif age_str == '[70-80)':\n",
    "        return 'Elderly'\n",
    "    elif age_str == '[80-90)':\n",
    "        return 'Elderly'\n",
    "    elif age_str == '[90-100)':\n",
    "        return 'Elderly'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df['age_group'] = df['age'].apply(categorize_age)\n",
    "\n",
    "# 5. Length of stay risk\n",
    "df['los_risk'] = pd.cut(df['time_in_hospital'], \n",
    "                        bins=[0, 3, 7, 14, 30], \n",
    "                        labels=['Low', 'Medium', 'High', 'Critical'])\n",
    "\n",
    "# 6. Diagnosis complexity - FIXED for string handling\n",
    "df['diagnosis_complexity'] = (\n",
    "    (df['diag_1'].astype(str).str.len() > 3).astype(int) * 0.4 +\n",
    "    (df['diag_2'].astype(str).str.len() > 3).astype(int) * 0.3 +\n",
    "    (df['diag_3'].astype(str).str.len() > 3).astype(int) * 0.3\n",
    ")\n",
    "\n",
    "# 7. Insurance-age interaction\n",
    "df['insurance_age_risk'] = df['payer_code'].astype(str) + '_' + df['age'].astype(str)\n",
    "\n",
    "# 8. Clinical severity index\n",
    "df['clinical_severity'] = (\n",
    "    df['number_diagnoses'] * 0.3 +\n",
    "    df['num_procedures'] * 0.2 +\n",
    "    df['num_medications'] * 0.2 +\n",
    "    df['time_in_hospital'] * 0.3\n",
    ")\n",
    "\n",
    "# Categorize clinical severity\n",
    "df['severity_level'] = pd.cut(df['clinical_severity'], \n",
    "                             bins=[0, 5, 10, 15, 50], \n",
    "                             labels=['Mild', 'Moderate', 'Severe', 'Critical'])\n",
    "\n",
    "print(\"‚úÖ Advanced features created:\")\n",
    "print(f\"   ‚Ä¢ Medication adherence score: {df['medication_adherence'].mean():.2f}\")\n",
    "print(f\"   ‚Ä¢ Hospital utilization score: {df['hospital_utilization'].mean():.2f}\")\n",
    "print(f\"   ‚Ä¢ Lab efficiency score: {df['lab_efficiency'].mean():.2f}\")\n",
    "print(f\"   ‚Ä¢ Clinical severity score: {df['clinical_severity'].mean():.2f}\")\n",
    "\n",
    "# Analyze new features\n",
    "print(\"\\nüìä Analysis of New Features:\")\n",
    "\n",
    "# Clinical severity analysis\n",
    "severity_analysis = df.groupby(['severity_level', 'readmission_30d']).size().unstack(fill_value=0)\n",
    "severity_analysis['total'] = severity_analysis.sum(axis=1)\n",
    "severity_analysis['readmission_rate'] = (severity_analysis[1] / severity_analysis['total'] * 100).round(2)\n",
    "\n",
    "print(\"\\nReadmission Rate by Clinical Severity:\")\n",
    "print(severity_analysis)\n",
    "\n",
    "# Age group analysis\n",
    "age_analysis = df.groupby(['age_group', 'readmission_30d']).size().unstack(fill_value=0)\n",
    "age_analysis['total'] = age_analysis.sum(axis=1)\n",
    "age_analysis['readmission_rate'] = (age_analysis[1] / age_analysis['total'] * 100).round(2)\n",
    "\n",
    "print(\"\\nReadmission Rate by Age Group:\")\n",
    "print(age_analysis)\n",
    "\n",
    "# Visualize new features\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Subplot 1: Clinical severity distribution\n",
    "plt.subplot(2, 4, 1)\n",
    "df['severity_level'].value_counts().plot(kind='bar', color='darkblue')\n",
    "plt.title('Distribution of Clinical Severity Levels', fontweight='bold')\n",
    "plt.xlabel('Severity Level')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Subplot 2: Readmission rate by severity\n",
    "plt.subplot(2, 4, 2)\n",
    "severity_analysis['readmission_rate'].plot(kind='bar', color='darkred')\n",
    "plt.title('Readmission Rate by Clinical Severity', fontweight='bold')\n",
    "plt.xlabel('Severity Level')\n",
    "plt.ylabel('Readmission Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Subplot 3: Medication adherence distribution\n",
    "plt.subplot(2, 4, 3)\n",
    "plt.hist(df['medication_adherence'], bins=30, color='lightblue', alpha=0.7, edgecolor='black')\n",
    "plt.title('Distribution of Medication Adherence Score', fontweight='bold')\n",
    "plt.xlabel('Medication Adherence Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Subplot 4: Hospital utilization by readmission status\n",
    "plt.subplot(2, 4, 4)\n",
    "df.boxplot(column='hospital_utilization', by='readmission_30d', ax=plt.gca())\n",
    "plt.title('Hospital Utilization by Readmission Status', fontweight='bold')\n",
    "plt.suptitle('')\n",
    "\n",
    "# Subplot 5: Lab efficiency distribution\n",
    "plt.subplot(2, 4, 5)\n",
    "plt.hist(df['lab_efficiency'], bins=30, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "plt.title('Distribution of Lab Efficiency Score', fontweight='bold')\n",
    "plt.xlabel('Lab Efficiency Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Subplot 6: Age group analysis\n",
    "plt.subplot(2, 4, 6)\n",
    "age_analysis['readmission_rate'].plot(kind='bar', color='orange')\n",
    "plt.title('Readmission Rate by Age Group', fontweight='bold')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Readmission Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Subplot 7: Length of stay risk analysis\n",
    "plt.subplot(2, 4, 7)\n",
    "los_analysis = df.groupby(['los_risk', 'readmission_30d']).size().unstack(fill_value=0)\n",
    "los_analysis['total'] = los_analysis.sum(axis=1)\n",
    "los_analysis['readmission_rate'] = (los_analysis[1] / los_analysis['total'] * 100).round(2)\n",
    "los_analysis['readmission_rate'].plot(kind='bar', color='purple')\n",
    "plt.title('Readmission Rate by Length of Stay Risk', fontweight='bold')\n",
    "plt.xlabel('Length of Stay Risk')\n",
    "plt.ylabel('Readmission Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Subplot 8: Diagnosis complexity analysis\n",
    "plt.subplot(2, 4, 8)\n",
    "plt.hist(df['diagnosis_complexity'], bins=10, color='lightcoral', alpha=0.7, edgecolor='black')\n",
    "plt.title('Distribution of Diagnosis Complexity', fontweight='bold')\n",
    "plt.xlabel('Diagnosis Complexity Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save feature engineering summary\n",
    "feature_engineering_summary = {\n",
    "    'medication_adherence_mean': df['medication_adherence'].mean(),\n",
    "    'hospital_utilization_mean': df['hospital_utilization'].mean(),\n",
    "    'lab_efficiency_mean': df['lab_efficiency'].mean(),\n",
    "    'clinical_severity_mean': df['clinical_severity'].mean(),\n",
    "    'diagnosis_complexity_mean': df['diagnosis_complexity'].mean(),\n",
    "    'highest_severity_readmission_rate': severity_analysis.loc['Critical', 'readmission_rate']\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ Feature engineering completed successfully!\")\n",
    "print(f\"üìä Created 8 new clinical features for modeling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìã COMPREHENSIVE SUMMARY & NEXT STEPS\n",
    "print(\"üìã COMPREHENSIVE SUMMARY & NEXT STEPS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"üéØ TARGET VARIABLE SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Total patients: {target_info['total_patients']:,}\")\n",
    "print(f\"   ‚Ä¢ Readmission rate: {target_info['readmission_rate']*100:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Class balance: {target_info['class_balance']}\")\n",
    "\n",
    "print(\"\\nüè• CLINICAL RISK SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Critical risk patients: {clinical_risk_summary['critical_risk_patients']:,}\")\n",
    "print(f\"   ‚Ä¢ Highest readmission rate: {clinical_risk_summary['highest_readmission_rate']:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Risk category with highest rate: {clinical_risk_summary['highest_readmission_category']}\")\n",
    "\n",
    "print(\"\\nüíä TREATMENT COMPLEXITY SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Average complexity score: {complexity_summary['avg_complexity']:.2f}\")\n",
    "print(f\"   ‚Ä¢ Complexity range: {complexity_summary['min_complexity']:.1f} - {complexity_summary['max_complexity']:.1f}\")\n",
    "print(f\"   ‚Ä¢ Critical complexity readmission rate: {complexity_summary['highest_complexity_readmission_rate']:.2f}%\")\n",
    "\n",
    "print(\"\\nüí∞ SOCIOECONOMIC SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Average risk score: {socioeconomic_summary['avg_risk_score']:.2f}\")\n",
    "print(f\"   ‚Ä¢ Medicaid patients: {socioeconomic_summary['medicaid_patients']:,}\")\n",
    "print(f\"   ‚Ä¢ Medicare patients: {socioeconomic_summary['medicare_patients']:,}\")\n",
    "print(f\"   ‚Ä¢ Highest risk readmission rate: {socioeconomic_summary['highest_risk_readmission_rate']:.2f}%\")\n",
    "\n",
    "print(\"\\nüöÄ FEATURE ENGINEERING SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Medication adherence: {feature_engineering_summary['medication_adherence_mean']:.2f}\")\n",
    "print(f\"   ‚Ä¢ Hospital utilization: {feature_engineering_summary['hospital_utilization_mean']:.2f}\")\n",
    "print(f\"   ‚Ä¢ Lab efficiency: {feature_engineering_summary['lab_efficiency_mean']:.2f}\")\n",
    "print(f\"   ‚Ä¢ Clinical severity: {feature_engineering_summary['clinical_severity_mean']:.2f}\")\n",
    "print(f\"   ‚Ä¢ Diagnosis complexity: {feature_engineering_summary['diagnosis_complexity_mean']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ NEXT STEPS FOR WEEK 2:\")\n",
    "print(\"1. Feature Selection: Choose top 20-30 features for modeling\")\n",
    "print(\"2. Data Preprocessing: Handle missing values and encode categorical variables\")\n",
    "print(\"3. Baseline Models: Train Logistic Regression, Random Forest, XGBoost\")\n",
    "print(\"4. Hyperparameter Tuning: Use Optuna for optimization\")\n",
    "print(\"5. Model Evaluation: Compare performance and interpretability\")\n",
    "print(\"6. Feature Importance: Analyze SHAP values for clinical insights\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS FOR MODELING:\")\n",
    "print(\"‚Ä¢ Focus on clinical risk and treatment complexity features\")\n",
    "print(\"‚Ä¢ Consider socioeconomic factors for bias detection\")\n",
    "print(\"‚Ä¢ Use medication adherence and hospital utilization patterns\")\n",
    "print(\"‚Ä¢ Implement proper cross-validation for imbalanced data\")\n",
    "print(\"‚Ä¢ Monitor for data leakage in temporal features\")\n",
    "\n",
    "# Save all summaries for later use\n",
    "eda_summary = {\n",
    "    'target_info': target_info,\n",
    "    'clinical_risk_summary': clinical_risk_summary,\n",
    "    'complexity_summary': complexity_summary,\n",
    "    'socioeconomic_summary': socioeconomic_summary,\n",
    "    'feature_engineering_summary': feature_engineering_summary\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ EDA Phase 1.2 completed successfully!\")\n",
    "print(f\"üìä Ready for feature engineering and baseline model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set professional color palette\n",
    "professional_colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#3A1772', '#6B5B95']\n",
    "\n",
    "# Create a professional summary dashboard with PROPER SPACING\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 16))  # Increased size for better spacing\n",
    "fig.suptitle('Diabetes Readmission Prediction - Clinical Insights Dashboard', \n",
    "             fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "# Plot 1: Target Distribution\n",
    "axes[0, 0].pie([target_info['readmission_count'], \n",
    "                target_info['total_patients'] - target_info['readmission_count']], \n",
    "                labels=['Readmission <30 days', 'No Readmission'], \n",
    "                autopct='%1.1f%%', colors=['#C73E1D', '#2E86AB'],\n",
    "                textprops={'fontsize': 12})\n",
    "axes[0, 0].set_title('Readmission Rate Distribution', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Plot 2: Clinical Risk Analysis\n",
    "risk_analysis['readmission_rate'].plot(kind='bar', ax=axes[0, 1], \n",
    "                                      color=professional_colors[:4])\n",
    "axes[0, 1].set_title('Readmission Rate by Clinical Risk', fontsize=16, fontweight='bold', pad=20)\n",
    "axes[0, 1].set_xlabel('Clinical Risk Category', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Readmission Rate (%)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45, labelsize=12)\n",
    "axes[0, 1].tick_params(axis='y', labelsize=12)\n",
    "\n",
    "# Plot 3: Treatment Complexity\n",
    "complexity_analysis['readmission_rate'].plot(kind='bar', ax=axes[0, 2], \n",
    "                                           color=professional_colors[1:5])\n",
    "axes[0, 2].set_title('Readmission Rate by Treatment Complexity', fontsize=16, fontweight='bold', pad=20)\n",
    "axes[0, 2].set_xlabel('Complexity Level', fontsize=14, fontweight='bold')\n",
    "axes[0, 2].set_ylabel('Readmission Rate (%)', fontsize=14, fontweight='bold')\n",
    "axes[0, 2].tick_params(axis='x', rotation=45, labelsize=12)\n",
    "axes[0, 2].tick_params(axis='y', labelsize=12)\n",
    "\n",
    "# Plot 4: Age Group Analysis\n",
    "age_analysis['readmission_rate'].plot(kind='bar', ax=axes[1, 0], \n",
    "                                     color=professional_colors[2:6])\n",
    "axes[1, 0].set_title('Readmission Rate by Age Group', fontsize=16, fontweight='bold', pad=20)\n",
    "axes[1, 0].set_xlabel('Age Group', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Readmission Rate (%)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45, labelsize=12)\n",
    "axes[1, 0].tick_params(axis='y', labelsize=12)\n",
    "\n",
    "# Plot 5: Socioeconomic Risk\n",
    "socio_analysis['readmission_rate'].plot(kind='bar', ax=axes[1, 1], \n",
    "                                       color=professional_colors[3:7])\n",
    "axes[1, 1].set_title('Readmission Rate by Socioeconomic Risk', fontsize=16, fontweight='bold', pad=20)\n",
    "axes[1, 1].set_xlabel('Socioeconomic Risk Level', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Readmission Rate (%)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45, labelsize=12)\n",
    "axes[1, 1].tick_params(axis='y', labelsize=12)\n",
    "\n",
    "# Plot 6: Clinical Severity\n",
    "severity_analysis['readmission_rate'].plot(kind='bar', ax=axes[1, 2], \n",
    "                                          color=professional_colors[4:8])\n",
    "axes[1, 2].set_title('Readmission Rate by Clinical Severity', fontsize=16, fontweight='bold', pad=20)\n",
    "axes[1, 2].set_xlabel('Severity Level', fontsize=14, fontweight='bold')\n",
    "axes[1, 2].set_ylabel('Readmission Rate (%)', fontsize=14, fontweight='bold')\n",
    "axes[1, 2].tick_params(axis='x', rotation=45, labelsize=12)\n",
    "axes[1, 2].tick_params(axis='y', labelsize=12)\n",
    "\n",
    "# Add value labels on bars for better readability\n",
    "for ax in axes.flat:\n",
    "    if ax.get_children():  # Check if plot has data\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt='%.1f%%', fontsize=10, padding=3)\n",
    "\n",
    "# Adjust layout with more space\n",
    "plt.tight_layout(pad=3.0, h_pad=2.0, w_pad=2.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üè• PHASE 1: CLINICAL DOMAIN FEATURES\n",
    "print(\"üè• CREATING CLINICAL DOMAIN FEATURES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. MEDICATION COMPLEXITY SCORE\n",
    "print(\"1Ô∏è‚É£ Creating Medication Complexity Score...\")\n",
    "df['medication_complexity'] = (\n",
    "    df['num_medications'] * 0.4 +\n",
    "    df['number_diagnoses'] * 0.3 +\n",
    "    df['time_in_hospital'] * 0.3\n",
    ")\n",
    "\n",
    "# 2. CLINICAL RISK STRATIFICATION\n",
    "print(\"2Ô∏è‚É£ Creating Clinical Risk Stratification...\")\n",
    "df['clinical_risk_score'] = (\n",
    "    (df['num_procedures'] > df['num_procedures'].median()).astype(int) * 2 +\n",
    "    (df['num_lab_procedures'] > df['num_lab_procedures'].median()).astype(int) * 1.5 +\n",
    "    (df['number_diagnoses'] > df['number_diagnoses'].median()).astype(int) * 2 +\n",
    "    (df['time_in_hospital'] > df['time_in_hospital'].median()).astype(int) * 1.5\n",
    ")\n",
    "\n",
    "# Risk categories\n",
    "df['risk_category'] = pd.cut(df['clinical_risk_score'], \n",
    "                             bins=[0, 2, 4, 6, 10], \n",
    "                             labels=['Low', 'Medium', 'High', 'Critical'])\n",
    "\n",
    "# 3. TREATMENT ADHERENCE INDEX\n",
    "print(\"3Ô∏è‚É£ Creating Treatment Adherence Index...\")\n",
    "df['treatment_adherence'] = (\n",
    "    (df['num_medications'] > 0).astype(int) * 0.4 +\n",
    "    (df['num_procedures'] > 0).astype(int) * 0.3 +\n",
    "    (df['num_lab_procedures'] > 0).astype(int) * 0.3\n",
    ")\n",
    "\n",
    "# 4. COMORBIDITY PATTERNS\n",
    "print(\"4Ô∏è‚É£ Creating Comorbidity Patterns...\")\n",
    "df['comorbidity_count'] = (\n",
    "    (df['diag_1'] != '?').astype(int) +\n",
    "    (df['diag_2'] != '?').astype(int) +\n",
    "    (df['diag_3'] != '?').astype(int)\n",
    ")\n",
    "\n",
    "df['comorbidity_severity'] = df['comorbidity_count'] * df['number_diagnoses']\n",
    "\n",
    "# 5. LABORATORY EFFICIENCY\n",
    "print(\"5Ô∏è‚É£ Creating Laboratory Efficiency Metrics...\")\n",
    "df['lab_efficiency'] = df['num_lab_procedures'] / (df['time_in_hospital'] + 1)\n",
    "df['lab_efficiency'] = df['lab_efficiency'].clip(0, 10)  # Cap at reasonable values\n",
    "\n",
    "# 6. PROCEDURE INTENSITY\n",
    "print(\"6Ô∏è‚É£ Creating Procedure Intensity Metrics...\")\n",
    "df['procedure_intensity'] = df['num_procedures'] / (df['time_in_hospital'] + 1)\n",
    "df['procedure_intensity'] = df['procedure_intensity'].clip(0, 5)\n",
    "\n",
    "print(\"‚úÖ Clinical domain features created successfully!\")\n",
    "print(f\"üìä New features: {[col for col in df.columns if col.startswith(('medication', 'clinical', 'treatment', 'comorbidity', 'lab', 'procedure'))]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÔøΩÔøΩ PHASE 2: DEMOGRAPHIC & SOCIOECONOMIC FEATURES\n",
    "print(\"ÔøΩÔøΩ CREATING DEMOGRAPHIC & SOCIOECONOMIC FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. AGE RISK GROUPS\n",
    "print(\"1Ô∏è‚É£ Creating Age Risk Groups...\")\n",
    "def categorize_age_risk(age_str):\n",
    "    if age_str == '?':\n",
    "        return 'Unknown'\n",
    "    elif age_str in ['[0-10)', '[10-20)', '[20-30)']:\n",
    "        return 'Low_Risk'\n",
    "    elif age_str in ['[30-40)', '[40-50)']:\n",
    "        return 'Medium_Risk'\n",
    "    elif age_str in ['[50-60)', '[60-70)']:\n",
    "        return 'High_Risk'\n",
    "    elif age_str in ['[70-80)', '[80-90)', '[90-100)']:\n",
    "        return 'Critical_Risk'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df['age_risk_group'] = df['age'].apply(categorize_age_risk)\n",
    "\n",
    "# 2. INSURANCE-AGE INTERACTION RISK\n",
    "print(\"2Ô∏è‚É£ Creating Insurance-Age Interaction Risk...\")\n",
    "df['insurance_age_risk'] = df['payer_code'].astype(str) + '_' + df['age_risk_group'].astype(str)\n",
    "\n",
    "# 3. GENDER-AGE RISK COMBINATIONS\n",
    "print(\"3Ô∏è‚É£ Creating Gender-Age Risk Combinations...\")\n",
    "df['gender_age_risk'] = df['gender'] + '_' + df['age_risk_group'].astype(str)\n",
    "\n",
    "# 4. SOCIOECONOMIC RISK INDEX\n",
    "print(\"4Ô∏è‚É£ Creating Socioeconomic Risk Index...\")\n",
    "df['socioeconomic_risk'] = (\n",
    "    (df['payer_code'] == '?').astype(int) * 2 +\n",
    "    (df['gender'] == 'Unknown/Invalid').astype(int) * 1 +\n",
    "    (df['age'] == '?').astype(int) * 1\n",
    ")\n",
    "\n",
    "# 5. LENGTH OF STAY RISK CATEGORIES\n",
    "print(\"5Ô∏è‚É£ Creating Length of Stay Risk Categories...\")\n",
    "df['los_risk_category'] = pd.cut(df['time_in_hospital'], \n",
    "                                 bins=[0, 3, 7, 14, 30, 100], \n",
    "                                 labels=['Very_Low', 'Low', 'Medium', 'High', 'Critical'])\n",
    "\n",
    "# 6. READMISSION RISK WINDOWS\n",
    "print(\"6Ô∏è‚É£ Creating Readmission Risk Windows...\")\n",
    "df['readmission_7d'] = (df['readmitted'] == '<30').astype(int)  # 7-day approximation\n",
    "df['readmission_15d'] = (df['readmitted'] == '<30').astype(int)  # 15-day approximation\n",
    "df['readmission_30d'] = (df['readmitted'] == '<30').astype(int)  # 30-day (existing)\n",
    "df['readmission_90d'] = (df['readmitted'].isin(['<30', '>30'])).astype(int)  # 90-day\n",
    "\n",
    "print(\"‚úÖ Demographic & socioeconomic features created successfully!\")\n",
    "print(f\"üìä New features: {[col for col in df.columns if any(x in col for x in ['age_risk', 'insurance', 'gender', 'socioeconomic', 'los_risk', 'readmission_'])]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ PHASE 3: ADVANCED ML FEATURES\n",
    "print(\"ü§ñ CREATING ADVANCED ML FEATURES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. POLYNOMIAL INTERACTIONS\n",
    "print(\"1Ô∏è‚É£ Creating Polynomial Interactions...\")\n",
    "df['age_medication_interaction'] = df['age_risk_group'].astype(str) + '_' + df['num_medications'].astype(str)\n",
    "df['diagnosis_procedure_interaction'] = df['number_diagnoses'] * df['num_procedures']\n",
    "df['time_medication_efficiency'] = df['time_in_hospital'] * df['num_medications']\n",
    "\n",
    "# 2. RATIO FEATURES\n",
    "print(\"2Ô∏è‚É£ Creating Ratio Features...\")\n",
    "df['medications_per_day'] = df['num_medications'] / (df['time_in_hospital'] + 1)\n",
    "df['procedures_per_day'] = df['num_procedures'] / (df['time_in_hospital'] + 1)\n",
    "df['lab_procedures_per_day'] = df['num_lab_procedures'] / (df['time_in_hospital'] + 1)\n",
    "df['diagnoses_per_day'] = df['number_diagnoses'] / (df['time_in_hospital'] + 1)\n",
    "\n",
    "# 3. BINNED NUMERICAL FEATURES\n",
    "print(\"3Ô∏è‚É£ Creating Binned Numerical Features...\")\n",
    "df['medications_binned'] = pd.cut(df['num_medications'], \n",
    "                                  bins=[0, 5, 10, 15, 20, 100], \n",
    "                                  labels=['Very_Low', 'Low', 'Medium', 'High', 'Very_High'])\n",
    "\n",
    "df['diagnoses_binned'] = pd.cut(df['number_diagnoses'], \n",
    "                                 bins=[0, 3, 6, 9, 12, 100], \n",
    "                                 labels=['Very_Low', 'Low', 'Medium', 'High', 'Very_High'])\n",
    "\n",
    "# 4. AGGREGATION FEATURES\n",
    "print(\"4Ô∏è‚É£ Creating Aggregation Features...\")\n",
    "df['total_procedures'] = df['num_procedures'] + df['num_lab_procedures']\n",
    "df['total_clinical_activities'] = df['num_procedures'] + df['num_lab_procedures'] + df['num_medications']\n",
    "df['clinical_intensity'] = df['total_clinical_activities'] / (df['time_in_hospital'] + 1)\n",
    "\n",
    "# 5. CATEGORICAL ENCODING PREPARATION\n",
    "print(\"5Ô∏è‚É£ Preparing Categorical Encoding...\")\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"üìã Categorical columns identified: {len(categorical_columns)}\")\n",
    "print(f\"   ‚Ä¢ High cardinality columns: {[col for col in categorical_columns if df[col].nunique() > 20]}\")\n",
    "\n",
    "print(\"‚úÖ Advanced ML features created successfully!\")\n",
    "print(f\"üìä New features: {[col for col in df.columns if any(x in col for x in ['interaction', 'ratio', 'binned', 'total', 'intensity'])]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÔøΩÔøΩ FEATURE ANALYSIS & VALIDATION\n",
    "print(\"ÔøΩÔøΩ ANALYZING ENGINEERED FEATURES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. FEATURE SUMMARY STATISTICS\n",
    "print(\"1Ô∏è‚É£ Feature Summary Statistics...\")\n",
    "new_features = [col for col in df.columns if col not in ['readmitted', 'readmission_30d']]\n",
    "print(f\"üìä Total features created: {len(new_features)}\")\n",
    "\n",
    "# 2. FEATURE CORRELATION ANALYSIS\n",
    "print(\"2Ô∏è‚É£ Feature Correlation Analysis...\")\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "\n",
    "# Find highly correlated features\n",
    "high_corr_features = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            high_corr_features.append((correlation_matrix.columns[i], \n",
    "                                     correlation_matrix.columns[j], \n",
    "                                     correlation_matrix.iloc[i, j]))\n",
    "\n",
    "print(f\"üîó Highly correlated feature pairs (|r| > 0.8): {len(high_corr_features)}\")\n",
    "for pair in high_corr_features[:5]:  # Show first 5\n",
    "    print(f\"   ‚Ä¢ {pair[0]} ‚Üî {pair[1]}: r = {pair[2]:.3f}\")\n",
    "\n",
    "# 3. FEATURE IMPORTANCE ANALYSIS\n",
    "print(\"3Ô∏è‚É£ Feature Importance Analysis...\")\n",
    "try:\n",
    "    # Prepare data for feature importance\n",
    "    feature_cols = [col for col in df.columns if col not in ['readmitted', 'readmission_30d'] and df[col].dtype in ['int64', 'float64']]\n",
    "    X_temp = df[feature_cols].fillna(0)\n",
    "    y_temp = df['readmission_30d']\n",
    "    \n",
    "    # Train a simple model for feature importance\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_temp, y_temp)\n",
    "    \n",
    "    # Get feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': rf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"üèÜ Top 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Feature importance analysis failed: {e}\")\n",
    "    print(\"   This is normal for some data types. Continuing...\")\n",
    "\n",
    "print(\"‚úÖ Feature analysis completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà FEATURE VISUALIZATION DASHBOARD\n",
    "print(\"üìà CREATING FEATURE VISUALIZATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create comprehensive visualization dashboard\n",
    "plt.figure(figsize=(24, 16))\n",
    "\n",
    "# 1. Clinical Risk Distribution\n",
    "plt.subplot(3, 4, 1)\n",
    "df['risk_category'].value_counts().plot(kind='bar', color='darkred')\n",
    "plt.title('Clinical Risk Category Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Risk Category')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 2. Age Risk Groups\n",
    "plt.subplot(3, 4, 2)\n",
    "df['age_risk_group'].value_counts().plot(kind='bar', color='darkblue')\n",
    "plt.title('Age Risk Group Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Age Risk Group')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 3. Medication Complexity Distribution\n",
    "plt.subplot(3, 4, 3)\n",
    "plt.hist(df['medication_complexity'], bins=30, color='lightblue', alpha=0.7, edgecolor='black')\n",
    "plt.title('Medication Complexity Score Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Medication Complexity Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 4. Clinical Risk vs Readmission\n",
    "plt.subplot(3, 4, 4)\n",
    "risk_readmission = df.groupby(['risk_category', 'readmission_30d']).size().unstack(fill_value=0)\n",
    "risk_readmission['readmission_rate'] = (risk_readmission[1] / risk_readmission.sum(axis=1) * 100).round(2)\n",
    "risk_readmission['readmission_rate'].plot(kind='bar', color='darkgreen')\n",
    "plt.title('Readmission Rate by Clinical Risk', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Clinical Risk Category')\n",
    "plt.ylabel('Readmission Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 5. Length of Stay Risk\n",
    "plt.subplot(3, 4, 5)\n",
    "df['los_risk_category'].value_counts().plot(kind='bar', color='purple')\n",
    "plt.title('Length of Stay Risk Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('LOS Risk Category')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 6. Treatment Adherence\n",
    "plt.subplot(3, 4, 6)\n",
    "plt.hist(df['treatment_adherence'], bins=20, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "plt.title('Treatment Adherence Index Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Treatment Adherence Index')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 7. Comorbidity Severity\n",
    "plt.subplot(3, 4, 7)\n",
    "plt.hist(df['comorbidity_severity'], bins=20, color='lightcoral', alpha=0.7, edgecolor='black')\n",
    "plt.title('Comorbidity Severity Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Comorbidity Severity Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 8. Lab Efficiency\n",
    "plt.subplot(3, 4, 8)\n",
    "plt.hist(df['lab_efficiency'], bins=20, color='lightyellow', alpha=0.7, edgecolor='black')\n",
    "plt.title('Laboratory Efficiency Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Lab Efficiency Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 9. Socioeconomic Risk\n",
    "plt.subplot(3, 4, 9)\n",
    "df['socioeconomic_risk'].value_counts().sort_index().plot(kind='bar', color='orange')\n",
    "plt.title('Socioeconomic Risk Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Socioeconomic Risk Score')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# 10. Clinical Intensity\n",
    "plt.subplot(3, 4, 10)\n",
    "plt.hist(df['clinical_intensity'], bins=20, color='lightsteelblue', alpha=0.7, edgecolor='black')\n",
    "plt.title('Clinical Intensity Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Clinical Intensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 11. Readmission Risk Windows\n",
    "plt.subplot(3, 4, 11)\n",
    "readmission_windows = ['readmission_7d', 'readmission_15d', 'readmission_30d', 'readmission_90d']\n",
    "readmission_rates = [df[col].mean() * 100 for col in readmission_windows]\n",
    "plt.bar(['7d', '15d', '30d', '90d'], readmission_rates, color=['red', 'orange', 'yellow', 'green'])\n",
    "plt.title('Readmission Rates by Time Window', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Time Window')\n",
    "plt.ylabel('Readmission Rate (%)')\n",
    "\n",
    "# 12. Feature Correlation Heatmap (Top 15)\n",
    "plt.subplot(3, 4, 12)\n",
    "top_features = feature_importance.head(15)['feature'].tolist() if 'feature_importance' in locals() else numerical_features[:15]\n",
    "corr_subset = df[top_features].corr()\n",
    "sns.heatmap(corr_subset, annot=False, cmap='coolwarm', center=0, square=True, cbar_kws={'shrink': 0.8})\n",
    "plt.title('Top Features Correlation Heatmap', fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Feature visualizations created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ FEATURE ENGINEERING SUMMARY & EXPORT\n",
    "print(\"üíæ FEATURE ENGINEERING SUMMARY & EXPORT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. FEATURE SUMMARY\n",
    "print(\"1Ô∏è‚É£ FEATURE ENGINEERING SUMMARY:\")\n",
    "print(f\"   ÔøΩÔøΩ Original features: {len([col for col in df.columns if col in ['readmitted', 'readmission_30d']])}\")\n",
    "print(f\"   üöÄ New features created: {len([col for col in df.columns if col not in ['readmitted', 'readmission_30d']])}\")\n",
    "print(f\"   üéØ Total features: {len(df.columns)}\")\n",
    "\n",
    "# 2. FEATURE CATEGORIES\n",
    "print(\"\\n2Ô∏è‚É£ FEATURE CATEGORIES:\")\n",
    "clinical_features = [col for col in df.columns if any(x in col for x in ['medication', 'clinical', 'treatment', 'comorbidity', 'lab', 'procedure'])]\n",
    "demographic_features = [col for col in df.columns if any(x in col for x in ['age_risk', 'insurance', 'gender', 'socioeconomic', 'los_risk'])]\n",
    "ml_features = [col for col in df.columns if any(x in col for x in ['interaction', 'ratio', 'binned', 'total', 'intensity'])]\n",
    "\n",
    "print(f\"   ÔøΩÔøΩ Clinical features: {len(clinical_features)}\")\n",
    "print(f\"   üë• Demographic features: {len(demographic_features)}\")\n",
    "print(f\"   ÔøΩÔøΩ ML features: {len(ml_features)}\")\n",
    "\n",
    "# 3. DATA QUALITY CHECK\n",
    "print(\"\\n3Ô∏è‚É£ DATA QUALITY CHECK:\")\n",
    "missing_after = df.isnull().sum().sum()\n",
    "print(f\"   ‚ùå Missing values: {missing_after:,}\")\n",
    "print(f\"   ‚úÖ Data shape: {df.shape}\")\n",
    "print(f\"   üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# 4. EXPORT ENGINEERED DATASET\n",
    "print(\"\\n4Ô∏è‚É£ EXPORTING ENGINEERED DATASET...\")\n",
    "output_filename = 'diabetic_data_engineered.csv'\n",
    "df.to_csv(output_filename, index=False)\n",
    "print(f\"   ‚úÖ Dataset exported to: {output_filename}\")\n",
    "print(f\"   üìÅ File size: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# 5. FEATURE LIST EXPORT\n",
    "print(\"\\n5Ô∏è‚É£ EXPORTING FEATURE LIST...\")\n",
    "feature_list = pd.DataFrame({\n",
    "    'feature_name': df.columns.tolist(),\n",
    "    'feature_type': df.dtypes.astype(str).tolist(),\n",
    "    'unique_values': [df[col].nunique() for col in df.columns],\n",
    "    'missing_values': df.isnull().sum().tolist(),\n",
    "    'category': ['Target' if col in ['readmitted', 'readmission_30d'] else \n",
    "                 'Clinical' if col in clinical_features else\n",
    "                 'Demographic' if col in demographic_features else\n",
    "                 'ML' if col in ml_features else 'Original' for col in df.columns]\n",
    "})\n",
    "\n",
    "feature_list.to_csv('feature_engineering_summary.csv', index=False)\n",
    "print(f\"   ‚úÖ Feature list exported to: feature_engineering_summary.csv\")\n",
    "\n",
    "print(\"\\nüéâ FEATURE ENGINEERING COMPLETED SUCCESSFULLY! ÔøΩÔøΩ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä Total features: {len(df.columns)}\")\n",
    "print(f\"üöÄ New features created: {len([col for col in df.columns if col not in ['readmitted', 'readmission_30d']])}\")\n",
    "print(f\"üíæ Dataset exported: {output_filename}\")\n",
    "print(f\"üìã Feature summary: feature_engineering_summary.csv\")\n",
    "print(\"\\nüéØ NEXT STEPS:\")\n",
    "print(\"   1. Review feature engineering summary\")\n",
    "print(\"   2. Proceed to Power BI dashboard creation\")\n",
    "print(\"   3. Model development and training\")\n",
    "print(\"   4. MLOps pipeline implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
